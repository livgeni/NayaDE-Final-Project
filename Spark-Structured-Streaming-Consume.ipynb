{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from sys import stdout\n",
    "\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "console_handler = logging.StreamHandler(stdout)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "logger = logging.getLogger('opensky.spark_consumer')\n",
    "logger.addHandler(console_handler)\n",
    "logger.setLevel('DEBUG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# # Topics/Brokers\n",
    "topic_real_time_states = \"real-time-states\"\n",
    "topic_raw_json = 'raw_json'\n",
    "topic_flat_json = 'flat_json'\n",
    "# topic_test = \"topic_test\"\n",
    "broker = \"localhost:9092\"\n",
    "\n",
    "host_name = 'cnt7-naya-cdh6'\n",
    "hive_host = \"localhost\"\n",
    "hdfs_host = \"localhost\"\n",
    "hdfs_port = 8020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.1 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"StructuredRealTimeState\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import functions as F\n",
    "import json\n",
    "\n",
    "schema = T.ArrayType(T.StructType()\\\n",
    ".add(\"time\", T.TimestampType())\\\n",
    " .add(\"icao24\", T.StringType())\\\n",
    " .add(\"callsign\", T.StringType())\\\n",
    ".add(\"last_contact\", T.TimestampType())\\\n",
    " .add(\"longitude\", T.FloatType())\\\n",
    "  .add(\"latitude\", T.FloatType())\\\n",
    "  .add(\"baro_altitude\", T.FloatType())\\\n",
    "  .add(\"on_ground\", T.IntegerType())\\\n",
    "  .add(\"velocity\", T.FloatType())\\\n",
    "  .add(\"geo_altitude\", T.FloatType())\\\n",
    "  .add(\"squawk\", T.StringType())\\\n",
    "  .add(\"position_source\", T.IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark \\\n",
    "#     .read \\\n",
    "#     .format(\"kafka\") \\\n",
    "#     .option(\"kafka.bootstrap.servers\", broker) \\\n",
    "#     .option(\"subscribe\", topic_real_time_states) \\\n",
    "#     .option(\"startingOffsets\", \"earliest\")\\\n",
    "#     .load()\\\n",
    "#     .select(F.from_json(F.col(\"value\").cast(\"string\"), schema).alias(\"value\"))\\\n",
    "#     .select((F.explode(\"value\").alias(\"value\")))\\\n",
    "#     .select(\"value.*\")\n",
    "    \n",
    "# #.selectExpr(\"CAST(value AS STRING)\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import urllib\n",
    "from impala.dbapi import connect\n",
    "\n",
    "def drop_old_partitions(impala_conn: connect, table_name:str, table_src_path:str, \n",
    "                             partition_name:str, earliest_time_to_keep:datetime.timestamp):\n",
    "    \"\"\"\n",
    "    Drop old partitions at path <table_src_path>, drop all partitions older than <earliest_time_to_keep>\n",
    "    First drop partitions through impala client (impala.dbapi), then delete folders\n",
    "    \"\"\"\n",
    "    logger.debug(f'dropping old partitions for table {table_name}, all partitions oldert than {earliest_time_to_keep}')\n",
    "    \n",
    "    fs = pa.hdfs.connect(\n",
    "            host=hdfs_host, \n",
    "            port=hdfs_port, \n",
    "            user='hdfs', \n",
    "            kerb_ticket=None, \n",
    "            driver='libhdfs', \n",
    "            extra_conf=None)\n",
    "\n",
    "\n",
    "    partition_pattern = r'(.+\\=(.+))'\n",
    "    partitions_paths = fs.ls(table_src_path)\n",
    "    partitions_tup = [re.findall(partition_pattern, partition_path) for partition_path in partitions_paths]\n",
    "    # partitions_tup is of form : (partition path, partition date)\n",
    "    # urllib.parse.unquote in order to turn special chars as %3A to regular (:) , aslo flatten the list\n",
    "    partitions_tup = [(pt[0][0], urllib.parse.unquote(pt[0][1])) for pt in partitions_tup if len(pt) > 0]\n",
    "    partitions_dict = {date : path for path, date in partitions_tup}\n",
    "\n",
    "    partitions_to_delete = [p_d for p_d in partitions_dict.keys() if datetime.strptime(p_d, '%Y-%m-%d %H:%M:%S') < earliest_time_to_keep]\n",
    "\n",
    "    # here partitions to_delete holds all partitions that should be deleted\n",
    "\n",
    "    crsr = impala_conn.cursor()\n",
    "\n",
    "    try:\n",
    "        for part_key in partitions_to_delete:\n",
    "            crsr.execute(f'alter table {table_name} drop if exists partition ({partition_name}=\"{part_key}\");')\n",
    "            fs.delete(partitions_dict[part_key], recursive=True)\n",
    "            logger.debug(f'deleted : {partitions_dict[part_key]}')\n",
    "    except Exception as ex:\n",
    "        logger.Error(ex)\n",
    "    finally:\n",
    "        crsr.close()\n",
    "        \n",
    "# earliest_time_to_keep = datetime.now() - timedelta(minutes=450)\n",
    "# table_src_path = '/user/naya/FinalProject/last_hour'\n",
    "# drop_old_partitions('opensky_network', \"states_last_hour\", table_src_path, \"date_minute\", earliest_time_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "# from pyhive import hive\n",
    "from datetime import datetime, timedelta\n",
    "from impala.dbapi import connect\n",
    "from os import path\n",
    "# import ibis.impala.client\n",
    "# import ibis.impala.api\n",
    "# import ibis.impala.ddl\n",
    "\n",
    "# # # Impala connection details:impala_host = 'localhost'\n",
    "# hdfs_host = 'localhost'\n",
    "# hdfs_port = 9870\n",
    "\n",
    "# impala_port = 21050\n",
    "# opensky_network_db = 'playground'\n",
    "# username = 'naya'\n",
    "# password = 'naya'\n",
    "# host = 'localhost'\n",
    "\n",
    "# hdfs = ibis.hdfs_connect(\n",
    "#   host = host, \n",
    "#   port = hdfs_port, \n",
    "#   protocol = 'webhdfs', \n",
    "#   use_https = 'default', \n",
    "#   auth_mechanism = 'NOSASL')\n",
    "\n",
    "# impala_client = ibis.impala.connect(\n",
    "#   host = host, \n",
    "#   port = impala_port, \n",
    "#   database = opensky_network_db, \n",
    "#   user = username, \n",
    "#   password = password, \n",
    "#   pool_size = 8, \n",
    "#   hdfs_client = hdfs)\n",
    "\n",
    "last_hour_table_name = 'last_hour'\n",
    "target_database = 'opensky_network'\n",
    "\n",
    "# root_data_path = '/user/naya/FinalProject/'\n",
    "# last_hour_path = path.join(root_data_path, 'last_hour')\n",
    "# last_day_path = path.join(root_data_path, 'last_day')\n",
    "# last_week_path = path.join(root_data_path,'last_week')\n",
    "\n",
    "def write_to_impala(df: DataFrame, epoch_id):\n",
    "    root_data_path = '/user/naya/FinalProject/'\n",
    "    last_hour_path = path.join(root_data_path, 'last_hour')\n",
    "    last_day_path = path.join(root_data_path, 'last_day')\n",
    "    last_week_path = path.join(root_data_path,'last_week')\n",
    "    \n",
    "    logger.info(f'write_to_hive: epoch_id: {epoch_id} len: {df.count()}')\n",
    "    # write to each table - minutes, hours, days\n",
    "    if df.count() != 0:\n",
    "        df.persist()\n",
    "        logger.debug(f'trying to write to : {last_hour_path}')\n",
    "        df.withColumn('date_minute', F.date_trunc('minute', df.time)).write\\\n",
    "                    .mode(\"append\")\\\n",
    "                    .partitionBy('date_minute')\\\n",
    "                    .parquet(f'hdfs://localhost:8020/{last_hour_path}')\n",
    "        logger.debug(f'Trying to write to : {last_day_path}')\n",
    "        df.withColumn('date_hour', F.date_trunc('hour', df.time)).write\\\n",
    "                    .mode(\"append\")\\\n",
    "                    .partitionBy('date_hour')\\\n",
    "                    .parquet(f'hdfs://localhost:8020/{last_day_path}')\n",
    "#         df.unpersist()\n",
    "\n",
    "        impala_conn = connect(host=host_name, database = target_database, user = 'naya', password = 'naya', auth_mechanism = 'NOSASL')\n",
    "\n",
    "        drop_old_partitions(impala_conn, 'states_last_hour', last_hour_path, \n",
    "                                 'date_minute', datetime.now() - timedelta(hours=1))\n",
    "        drop_old_partitions(impala_conn, 'states_last_day', last_day_path, \n",
    "                                 'date_hour', datetime.now() - timedelta(hours=24))\n",
    "\n",
    "        impala_crsr = impala_conn.cursor()\n",
    "        try:\n",
    "            for table_name in ['states_last_hour', 'states_last_day']:\n",
    "                impala_crsr.execute(f'alter table {table_name} recover partitions;')\n",
    "                impala_crsr.execute(f'refresh {table_name};')\n",
    "        except Exception as ex:\n",
    "            logger.error(ex)\n",
    "        finally:\n",
    "            impala_crsr.close()\n",
    "            \n",
    "#         crsr.execute(f'show partitions {table_name};')\n",
    "#         logger.debug([d for d, *rest in crsr.fetchall()])\n",
    "    \n",
    "#     impala_client.table(last_hour_table_name).drop_partition('date_minute=2019-12-28 12:13:00')\n",
    "#     impala_client.table(last_hour_table_name).alter()\n",
    "#     impala_client.table(last_hour_table_name).refresh()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", broker) \\\n",
    "    .option(\"subscribe\", topic_real_time_states) \\\n",
    "    .option(\"startingOffsets\", \"latest\")\\\n",
    "    .load()\n",
    "\n",
    "state_vectors_df = df.select(F.from_json(F.col(\"value\").cast(\"string\"), schema).alias(\"value\"))\\\n",
    "                        .select((F.explode(\"value\").alias(\"value\")))\\\n",
    "                        .select(\"value.*\")\n",
    "\n",
    "# agg_count = state_vectors_df.withWatermark(\"time\", \"1 minute\").groupBy(\"time\").count()\n",
    "# query = agg_count\\\n",
    "#             .writeStream\\\n",
    "#             .outputMode(\"append\")\\\n",
    "#             .format(\"console\") \\\n",
    "#             .start()\n",
    "\n",
    "# # Write to parquet file\n",
    "# TBD - handle target path creation\n",
    "parquet_path = 'hdfs://cnt7-naya-cdh6.org:8020/FinalProject/hourly'\n",
    "parquet_checkpoint_path = \"/home/naya/parquet_checkpoint\"\n",
    "parquet_write = state_vectors_df\\\n",
    "                .withColumn('date_hour', F.date_trunc('hour', state_vectors_df.time))\\\n",
    "                .writeStream\\\n",
    "                .outputMode(\"append\")\\\n",
    "                .format(\"parquet\")\\\n",
    "                .partitionBy('date_hour')\\\n",
    "                .option(\"checkpointLocation\", parquet_checkpoint_path)\\\n",
    "                .option(\"path\", parquet_path)\\\n",
    "                .start()\n",
    "\n",
    "\n",
    "\n",
    "# query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-30 22:31:57,041 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 0 len: 0\n",
      "2019-12-30 22:32:06,310 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 1 len: 7997\n",
      "2019-12-30 22:32:06,673 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:32:07,937 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:32:08,215 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:32:08.215108\n",
      "2019-12-30 22:32:09,590 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A08%3A00\n",
      "2019-12-30 22:32:09,625 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A09%3A00\n",
      "2019-12-30 22:32:09,657 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A10%3A00\n",
      "2019-12-30 22:32:09,687 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A11%3A00\n",
      "2019-12-30 22:32:09,715 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A12%3A00\n",
      "2019-12-30 22:32:09,749 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A13%3A00\n",
      "2019-12-30 22:32:09,780 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A14%3A00\n",
      "2019-12-30 22:32:09,818 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A15%3A00\n",
      "2019-12-30 22:32:09,872 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A16%3A00\n",
      "2019-12-30 22:32:09,950 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A17%3A00\n",
      "2019-12-30 22:32:09,984 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A18%3A00\n",
      "2019-12-30 22:32:10,026 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A19%3A00\n",
      "2019-12-30 22:32:10,072 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A20%3A00\n",
      "2019-12-30 22:32:10,107 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A21%3A00\n",
      "2019-12-30 22:32:10,142 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A22%3A00\n",
      "2019-12-30 22:32:10,178 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A23%3A00\n",
      "2019-12-30 22:32:10,215 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A24%3A00\n",
      "2019-12-30 22:32:10,257 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A25%3A00\n",
      "2019-12-30 22:32:10,285 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A26%3A00\n",
      "2019-12-30 22:32:10,327 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A27%3A00\n",
      "2019-12-30 22:32:10,398 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A28%3A00\n",
      "2019-12-30 22:32:10,428 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A29%3A00\n",
      "2019-12-30 22:32:10,455 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A30%3A00\n",
      "2019-12-30 22:32:10,486 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A31%3A00\n",
      "2019-12-30 22:32:10,511 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A32%3A00\n",
      "2019-12-30 22:32:10,614 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:32:10.614480\n",
      "2019-12-30 22:32:20,855 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 2 len: 8003\n",
      "2019-12-30 22:32:21,370 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:32:22,164 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:32:22,418 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:32:22.418033\n",
      "2019-12-30 22:32:22,552 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:32:22.552623\n",
      "2019-12-30 22:32:35,962 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 3 len: 8012\n",
      "2019-12-30 22:32:36,470 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:32:37,112 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:32:37,278 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:32:37.278359\n",
      "2019-12-30 22:32:37,409 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:32:37.409088\n",
      "2019-12-30 22:32:49,578 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 4 len: 8007\n",
      "2019-12-30 22:32:50,104 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:32:50,700 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:32:51,302 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:32:51.302561\n",
      "2019-12-30 22:32:51,431 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:32:51.431671\n",
      "2019-12-30 22:33:03,851 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 5 len: 8015\n",
      "2019-12-30 22:33:04,369 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:33:04,961 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:33:05,503 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:33:05.503574\n",
      "2019-12-30 22:33:05,548 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A33%3A00\n",
      "2019-12-30 22:33:05,651 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:33:05.651336\n",
      "2019-12-30 22:33:18,933 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 6 len: 7987\n",
      "2019-12-30 22:33:19,389 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:33:20,351 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:33:20,908 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:33:20.908431\n",
      "2019-12-30 22:33:21,038 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:33:21.037910\n",
      "2019-12-30 22:33:34,802 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 7 len: 7984\n",
      "2019-12-30 22:33:35,299 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:33:35,899 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:33:36,104 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:33:36.104677\n",
      "2019-12-30 22:33:36,230 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:33:36.230039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-30 22:33:51,283 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 8 len: 8006\n",
      "2019-12-30 22:33:51,751 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:33:52,333 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:33:52,493 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:33:52.493205\n",
      "2019-12-30 22:33:52,616 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:33:52.616603\n",
      "2019-12-30 22:34:06,863 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 9 len: 8045\n",
      "2019-12-30 22:34:07,364 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:34:08,373 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:34:09,009 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:34:09.009622\n",
      "2019-12-30 22:34:09,056 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A34%3A00\n",
      "2019-12-30 22:34:09,160 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:34:09.160075\n",
      "2019-12-30 22:34:22,565 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 10 len: 8043\n",
      "2019-12-30 22:34:23,068 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:34:24,059 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:34:24,217 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:34:24.217106\n",
      "2019-12-30 22:34:24,340 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:34:24.340296\n",
      "2019-12-30 22:34:37,945 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 11 len: 8065\n",
      "2019-12-30 22:34:38,474 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:34:39,035 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:34:39,196 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:34:39.196890\n",
      "2019-12-30 22:34:39,328 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:34:39.328810\n",
      "2019-12-30 22:34:55,289 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 12 len: 8031\n",
      "2019-12-30 22:34:55,825 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:34:56,430 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:34:56,597 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:34:56.597823\n",
      "2019-12-30 22:34:56,720 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:34:56.720780\n",
      "2019-12-30 22:35:13,336 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 13 len: 8027\n",
      "2019-12-30 22:35:13,806 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:35:14,370 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:35:14,514 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:35:14.514927\n",
      "2019-12-30 22:35:14,564 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A35%3A00\n",
      "2019-12-30 22:35:14,666 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:35:14.666663\n",
      "2019-12-30 22:35:29,358 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 14 len: 8024\n",
      "2019-12-30 22:35:29,875 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:35:30,453 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:35:30,591 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:35:30.591338\n",
      "2019-12-30 22:35:30,722 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:35:30.722007\n",
      "2019-12-30 22:35:46,469 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 15 len: 8041\n",
      "2019-12-30 22:35:46,973 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:35:47,571 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:35:48,128 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:35:48.128573\n",
      "2019-12-30 22:35:48,253 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:35:48.253152\n",
      "2019-12-30 22:36:02,926 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 16 len: 8030\n",
      "2019-12-30 22:36:03,443 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:36:04,032 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:36:04,182 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:36:04.182688\n",
      "2019-12-30 22:36:04,230 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A36%3A00\n",
      "2019-12-30 22:36:04,340 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:36:04.340356\n",
      "2019-12-30 22:36:25,567 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 17 len: 8051\n",
      "2019-12-30 22:36:26,086 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:36:26,677 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:36:26,831 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:36:26.831148\n",
      "2019-12-30 22:36:26,952 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:36:26.951879\n",
      "2019-12-30 22:36:43,660 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 18 len: 8036\n",
      "2019-12-30 22:36:44,179 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:36:44,777 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:36:44,907 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:36:44.907085\n",
      "2019-12-30 22:36:45,027 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:36:45.027469\n",
      "2019-12-30 22:37:00,434 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 19 len: 8059\n",
      "2019-12-30 22:37:00,965 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:37:01,528 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:37:01,665 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:37:01.665087\n",
      "2019-12-30 22:37:01,712 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A37%3A00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-30 22:37:01,815 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:37:01.815239\n",
      "2019-12-30 22:37:17,626 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 20 len: 8054\n",
      "2019-12-30 22:37:18,146 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:37:18,743 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:37:18,873 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:37:18.873676\n",
      "2019-12-30 22:37:18,995 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:37:18.995288\n",
      "2019-12-30 22:37:36,918 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 21 len: 8040\n",
      "2019-12-30 22:37:37,448 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:37:38,057 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:37:38,242 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:37:38.242119\n",
      "2019-12-30 22:37:38,370 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:37:38.370229\n",
      "2019-12-30 22:37:54,811 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 22 len: 8023\n",
      "2019-12-30 22:37:55,314 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:37:56,307 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:37:56,446 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:37:56.446470\n",
      "2019-12-30 22:37:56,569 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:37:56.569340\n",
      "2019-12-30 22:38:14,374 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 23 len: 8033\n",
      "2019-12-30 22:38:14,895 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:38:15,495 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:38:15,658 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:38:15.658061\n",
      "2019-12-30 22:38:15,717 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A38%3A00\n",
      "2019-12-30 22:38:15,820 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:38:15.820428\n",
      "2019-12-30 22:38:34,274 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 24 len: 8028\n",
      "2019-12-30 22:38:34,794 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:38:35,375 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:38:35,501 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:38:35.501036\n",
      "2019-12-30 22:38:35,621 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:38:35.620922\n",
      "2019-12-30 22:38:52,738 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 25 len: 8038\n",
      "2019-12-30 22:38:53,243 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:38:53,866 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:38:53,997 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:38:53.997741\n",
      "2019-12-30 22:38:54,120 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:38:54.120681\n",
      "2019-12-30 22:39:11,338 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 26 len: 8043\n",
      "2019-12-30 22:39:11,850 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:39:12,440 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:39:12,566 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:39:12.566632\n",
      "2019-12-30 22:39:12,621 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A39%3A00\n",
      "2019-12-30 22:39:12,724 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:39:12.724328\n",
      "2019-12-30 22:39:31,572 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 27 len: 8017\n",
      "2019-12-30 22:39:32,098 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:39:33,107 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:39:33,241 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:39:33.241585\n",
      "2019-12-30 22:39:33,362 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:39:33.362230\n",
      "2019-12-30 22:39:52,835 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 28 len: 7991\n",
      "2019-12-30 22:39:53,350 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:39:53,990 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:39:54,541 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:39:54.541829\n",
      "2019-12-30 22:39:54,662 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:39:54.662341\n",
      "2019-12-30 22:40:13,029 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 29 len: 7981\n",
      "2019-12-30 22:40:13,553 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:40:14,113 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:40:14,256 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:40:14.256025\n",
      "2019-12-30 22:40:14,307 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A40%3A00\n",
      "2019-12-30 22:40:14,409 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:40:14.409722\n",
      "2019-12-30 22:40:33,461 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 30 len: 7989\n",
      "2019-12-30 22:40:33,983 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:40:34,559 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:40:34,704 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:40:34.704122\n",
      "2019-12-30 22:40:34,830 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:40:34.830469\n",
      "2019-12-30 22:40:53,976 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 31 len: 7982\n",
      "2019-12-30 22:40:54,487 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:40:55,081 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:40:55,260 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:40:55.260741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-30 22:40:55,383 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:40:55.383544\n",
      "2019-12-30 22:41:14,240 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 32 len: 7985\n",
      "2019-12-30 22:41:14,766 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:41:15,362 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:41:15,512 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:41:15.512021\n",
      "2019-12-30 22:41:15,566 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A41%3A00\n",
      "2019-12-30 22:41:15,671 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:41:15.670801\n",
      "2019-12-30 22:41:35,954 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 33 len: 8002\n",
      "2019-12-30 22:41:36,474 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:41:37,039 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:41:37,178 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:41:37.178838\n",
      "2019-12-30 22:41:37,302 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:41:37.302823\n",
      "2019-12-30 22:41:56,854 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 34 len: 7980\n",
      "2019-12-30 22:41:57,366 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:41:57,930 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:41:58,060 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:41:58.060295\n",
      "2019-12-30 22:41:58,179 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:41:58.179805\n",
      "2019-12-30 22:42:17,744 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 35 len: 7997\n",
      "2019-12-30 22:42:18,262 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:42:18,863 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:42:19,408 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:42:19.408745\n",
      "2019-12-30 22:42:19,450 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A42%3A00\n",
      "2019-12-30 22:42:19,553 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:42:19.553616\n",
      "2019-12-30 22:42:38,894 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 36 len: 7994\n",
      "2019-12-30 22:42:39,424 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:42:39,988 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:42:40,111 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:42:40.111411\n",
      "2019-12-30 22:42:40,233 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:42:40.232919\n",
      "2019-12-30 22:43:00,476 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 37 len: 8017\n",
      "2019-12-30 22:43:00,992 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:43:01,565 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:43:01,696 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:43:01.696634\n",
      "2019-12-30 22:43:01,744 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A43%3A00\n",
      "2019-12-30 22:43:01,847 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:43:01.847399\n",
      "2019-12-30 22:43:23,083 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 38 len: 8043\n",
      "2019-12-30 22:43:23,612 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:43:24,167 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:43:24,306 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:43:24.306551\n",
      "2019-12-30 22:43:24,424 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:43:24.424478\n",
      "2019-12-30 22:43:45,127 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 39 len: 8057\n",
      "2019-12-30 22:43:45,637 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:43:46,197 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:43:46,316 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:43:46.316157\n",
      "2019-12-30 22:43:46,434 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:43:46.434383\n",
      "2019-12-30 22:44:08,758 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 40 len: 8068\n",
      "2019-12-30 22:44:09,273 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:44:10,264 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:44:10,805 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:44:10.804979\n",
      "2019-12-30 22:44:10,880 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A44%3A00\n",
      "2019-12-30 22:44:10,983 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:44:10.983215\n",
      "2019-12-30 22:44:32,563 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 41 len: 8059\n",
      "2019-12-30 22:44:33,077 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:44:33,645 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:44:33,793 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:44:33.793158\n",
      "2019-12-30 22:44:33,915 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:44:33.915205\n",
      "2019-12-30 22:44:56,858 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 42 len: 8043\n",
      "2019-12-30 22:44:57,370 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:44:57,921 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:44:58,522 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:44:58.522762\n",
      "2019-12-30 22:44:58,643 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:44:58.643464\n",
      "2019-12-30 22:45:19,925 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 43 len: 8060\n",
      "2019-12-30 22:45:20,447 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:45:21,021 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-30 22:45:21,156 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:45:21.156770\n",
      "2019-12-30 22:45:21,205 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A45%3A00\n",
      "2019-12-30 22:45:21,309 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:45:21.308900\n",
      "2019-12-30 22:45:42,624 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 44 len: 8062\n",
      "2019-12-30 22:45:43,144 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:45:43,723 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:45:43,853 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:45:43.853604\n",
      "2019-12-30 22:45:43,972 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:45:43.972824\n",
      "2019-12-30 22:46:06,297 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 45 len: 8058\n",
      "2019-12-30 22:46:06,808 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:46:07,789 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:46:07,937 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:46:07.937107\n",
      "2019-12-30 22:46:07,980 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A46%3A00\n",
      "2019-12-30 22:46:08,083 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:46:08.083576\n",
      "2019-12-30 22:46:29,885 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 46 len: 8032\n",
      "2019-12-30 22:46:30,417 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:46:30,973 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:46:31,512 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:46:31.512479\n",
      "2019-12-30 22:46:31,636 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:46:31.635905\n",
      "2019-12-30 22:46:54,732 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 47 len: 8025\n",
      "2019-12-30 22:46:55,240 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:46:56,233 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:46:56,395 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:46:56.395096\n",
      "2019-12-30 22:46:56,522 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:46:56.522855\n",
      "2019-12-30 22:47:18,690 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 48 len: 8051\n",
      "2019-12-30 22:47:19,212 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:47:19,815 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:47:19,939 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:47:19.939903\n",
      "2019-12-30 22:47:19,986 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A47%3A00\n",
      "2019-12-30 22:47:20,094 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:47:20.094018\n",
      "2019-12-30 22:47:42,441 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 49 len: 8061\n",
      "2019-12-30 22:47:42,950 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:47:43,514 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:47:44,044 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:47:44.044372\n",
      "2019-12-30 22:47:44,162 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:47:44.162695\n",
      "2019-12-30 22:48:06,861 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 50 len: 8051\n",
      "2019-12-30 22:48:07,384 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:48:07,949 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:48:08,469 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:48:08.469343\n",
      "2019-12-30 22:48:08,511 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A48%3A00\n",
      "2019-12-30 22:48:08,614 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:48:08.614492\n",
      "2019-12-30 22:48:33,415 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 51 len: 8054\n",
      "2019-12-30 22:48:33,938 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:48:34,502 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:48:34,626 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:48:34.626740\n",
      "2019-12-30 22:48:34,748 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:48:34.748070\n",
      "2019-12-30 22:48:46,904 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 52 len: 8078\n",
      "2019-12-30 22:48:47,408 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:48:48,004 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:48:48,155 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:48:48.155247\n",
      "2019-12-30 22:48:48,275 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:48:48.275460\n",
      "2019-12-30 22:49:00,417 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 53 len: 8063\n",
      "2019-12-30 22:49:00,935 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:49:01,506 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:49:01,637 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:49:01.637256\n",
      "2019-12-30 22:49:01,680 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A49%3A00\n",
      "2019-12-30 22:49:01,787 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:49:01.787592\n",
      "2019-12-30 22:49:14,531 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 54 len: 8060\n",
      "2019-12-30 22:49:15,052 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:49:15,646 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:49:15,824 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:49:15.824027\n",
      "2019-12-30 22:49:15,946 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:49:15.946585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-30 22:49:29,351 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 55 len: 8047\n",
      "2019-12-30 22:49:29,859 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:49:30,426 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:49:30,559 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:49:30.559308\n",
      "2019-12-30 22:49:30,684 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:49:30.684470\n",
      "2019-12-30 22:49:43,424 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 56 len: 8088\n",
      "2019-12-30 22:49:43,940 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:49:44,553 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:49:44,707 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:49:44.707792\n",
      "2019-12-30 22:49:44,834 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:49:44.834771\n",
      "2019-12-30 22:49:58,331 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 57 len: 8088\n",
      "2019-12-30 22:49:58,840 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:49:59,406 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:49:59,938 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:49:59.938054\n",
      "2019-12-30 22:50:00,062 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:50:00.062058\n",
      "2019-12-30 22:50:13,581 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 58 len: 8094\n",
      "2019-12-30 22:50:14,093 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:50:14,681 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:50:14,827 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:50:14.827822\n",
      "2019-12-30 22:50:14,872 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A50%3A00\n",
      "2019-12-30 22:50:14,975 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:50:14.975283\n",
      "2019-12-30 22:50:31,204 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 59 len: 8078\n",
      "2019-12-30 22:50:31,747 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:50:32,682 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:50:32,807 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:50:32.807858\n",
      "2019-12-30 22:50:32,928 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:50:32.928743\n",
      "2019-12-30 22:50:46,995 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 60 len: 8093\n",
      "2019-12-30 22:50:47,503 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:50:48,082 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:50:48,221 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:50:48.221697\n",
      "2019-12-30 22:50:48,341 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:50:48.341477\n",
      "2019-12-30 22:51:02,795 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 61 len: 8096\n",
      "2019-12-30 22:51:03,297 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:51:03,875 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:51:04,002 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:51:04.002123\n",
      "2019-12-30 22:51:04,045 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A51%3A00\n",
      "2019-12-30 22:51:04,148 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:51:04.148567\n",
      "2019-12-30 22:51:20,665 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 62 len: 8117\n",
      "2019-12-30 22:51:21,174 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:51:22,172 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:51:22,335 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:51:22.335648\n",
      "2019-12-30 22:51:22,458 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:51:22.457881\n",
      "2019-12-30 22:51:37,015 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 63 len: 8108\n",
      "2019-12-30 22:51:37,504 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:51:38,120 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:51:38,279 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:51:38.279548\n",
      "2019-12-30 22:51:38,405 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:51:38.404936\n",
      "2019-12-30 22:51:53,718 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 64 len: 8098\n",
      "2019-12-30 22:51:54,304 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:51:54,901 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:51:55,136 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:51:55.136196\n",
      "2019-12-30 22:51:55,272 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:51:55.272195\n",
      "2019-12-30 22:52:10,467 - opensky.spark_consumer - INFO - write_to_hive: epoch_id: 65 len: 8117\n",
      "2019-12-30 22:52:10,978 - opensky.spark_consumer - DEBUG - trying to write to : /user/naya/FinalProject/last_hour\n",
      "2019-12-30 22:52:11,584 - opensky.spark_consumer - DEBUG - Trying to write to : /user/naya/FinalProject/last_day\n",
      "2019-12-30 22:52:11,749 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_hour, all partitions oldert than 2019-12-30 21:52:11.749441\n",
      "2019-12-30 22:52:11,800 - opensky.spark_consumer - DEBUG - deleted : /user/naya/FinalProject/last_hour/date_minute=2019-12-30 21%3A52%3A00\n",
      "2019-12-30 22:52:11,904 - opensky.spark_consumer - DEBUG - dropping old partitions for table states_last_day, all partitions oldert than 2019-12-29 22:52:11.903897\n"
     ]
    }
   ],
   "source": [
    "hive_write = state_vectors_df\\\n",
    "            .writeStream\\\n",
    "            .foreachBatch(write_to_impala)\\\n",
    "            .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query.isActive\n",
    "# parquet_write.recentProgress\n",
    "# query.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41285)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naya/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naya/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:41285)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-9ebbdfc45694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparquet_write\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misActive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(query.isActive)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36misActive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \"\"\"Whether this streaming query is currently active or not.\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misActive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    981\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \"\"\"\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    936\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:41285)"
     ]
    }
   ],
   "source": [
    "print(parquet_write.isActive)\n",
    "# print(query.isActive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_write.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41285)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naya/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naya/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:41285)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-909e44f7ecf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhive_write\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misActive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36misActive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \"\"\"Whether this streaming query is currently active or not.\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misActive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    981\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \"\"\"\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    936\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:41285)"
     ]
    }
   ],
   "source": [
    "hive_write.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hive_write.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword can't be an expression (<ipython-input-16-7ba5617340db>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-7ba5617340db>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    timedelta('hour'=1)\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword can't be an expression\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select date_trunc('hour', time), cast(last_contact as timestamp) from states limit 20;\n",
    "\n",
    "\n",
    "CREATE EXTERNAL TABLE playground.states_hourly\n",
    "(time TIMESTAMP, icao24 STRING, callsign STRING, last_contact TIMESTAMP,\n",
    "longitude FLOAT, latitude FLOAT, baro_altitude FLOAT, on_ground INT,   \n",
    "velocity FLOAT, geo_altitude FLOAT, squawk STRING, position_source INT)\n",
    "PARTITIONED BY (date_hour string)\n",
    "STORED AS PARQUET \n",
    "LOCATION 'hdfs://cnt7-naya-cdh6.org:8020/FinalProject/hourly';\n",
    "\n",
    "\n",
    "SHOW CREATE TABLE states;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
